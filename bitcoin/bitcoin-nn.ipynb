{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "%matplotlib inline \n",
    "\n",
    "LABEL_TO_INDEX = {-1: 0, 0: 1, 1: 2}\n",
    "\n",
    "# Parameters\n",
    "d = 5  # recommendation is < log3(T / 100), where T is number of available time units\n",
    "theta = 0.0\n",
    "confidence = 0.1\n",
    "startTrain = '2016-01-01'\n",
    "endTrain = '2016-03-30'\n",
    "startTest = '2016-05-01'\n",
    "endTest = '2016-05-15'\n",
    "\n",
    "def loadData():\n",
    "    df = pd.read_csv('btcnCNY_1-min_data_2012-01-01_to_2017-05-31.csv', usecols=[0,4])\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "    df.set_index('Timestamp', inplace=True)\n",
    "    return df\n",
    "\n",
    "def normalize(x):\n",
    "    if x.Close > theta:\n",
    "        return 1\n",
    "    elif x.Close < -theta:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "# feature vector [last price diff, count of -1, 0, 1, longest consecutive -1, 0, 1]\n",
    "def extractFeaturesAndLabels(prices):\n",
    "    # history of price differences\n",
    "    diff = prices.diff()\n",
    "    h = diff.apply(normalize,'columns') \n",
    "\n",
    "    numSamples = len(h)-d\n",
    "\n",
    "    # feature 1 - last price movement (use quantized value or actual price diff?) [should be actual price diff]\n",
    "    X = np.array(h[d-1:len(h)-1]).reshape((numSamples,1))\n",
    "\n",
    "    # feature 2 - tally counts\n",
    "    cnt,cnts = collections.Counter(h[:d]),[]\n",
    "    for i in range(numSamples):\n",
    "        cnts += [[cnt[-1],cnt[0],cnt[1]]]\n",
    "        cnt[h[i]] -= 1\n",
    "        cnt[h[i+d]] += 1\n",
    "    X = np.append(X, cnts, axis=1)    \n",
    "\n",
    "    # feature 3 - longest consecutive run (-1,0,1)\n",
    "    runs = []\n",
    "    for i in range(d-1,numSamples+d-1):\n",
    "        run, label = 0,h[i]\n",
    "        for j in range(d):\n",
    "            if h[i-j]==label:\n",
    "                run += 1\n",
    "            else:\n",
    "                break\n",
    "        runs.append(buildConsecutiveRunRow(label, run))\n",
    "    X = np.append(X, runs, axis=1)\n",
    "        \n",
    "    return X, to_categorical(h[d:].values+1)\n",
    "\n",
    "def extractFeaturesAndLabels2(prices):\n",
    "    q = prices.diff().apply(normalize, 'columns')\n",
    "    numSamples = len(q)-d\n",
    "    X = np.ndarray(shape=(numSamples, d))\n",
    "    for i in range(numSamples):\n",
    "        X[i,:] = q[i:i+d]\n",
    "    return X, to_categorical(q[d:].values+1)\n",
    "\n",
    "def buildConsecutiveRunRow(label, run):\n",
    "    ret = [0, 0, 0]\n",
    "    ret[LABEL_TO_INDEX[label]] = run\n",
    "    return ret\n",
    "\n",
    "def scoreIgnoreZeros(X, y):    \n",
    "    y_predict = clf.predict_proba(X)\n",
    "    total,correct = 0,0\n",
    "    for i,yp in enumerate(y_predict):\n",
    "        if yp[0] > confidence or yp[2] > confidence:\n",
    "            # -1,1 > than confidence threshold. classes are [-1, 0, 1]\n",
    "            p = -1 if yp[0] > confidence else 1\n",
    "            correct += 1 if p==y[i] else 0\n",
    "            total += 1\n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################## Load and preprocess data ##############\n",
    "df = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################# Extract features and labels ############\n",
    "X_train,y_train = extractFeaturesAndLabels(df[startTrain:endTrain])\n",
    "\n",
    "X_test, y_test = extractFeaturesAndLabels(df[startTest:endTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129595/129595 [==============================] - 3s - loss: 0.8148 - acc: 0.5187     \n",
      "Epoch 2/10\n",
      "129595/129595 [==============================] - 3s - loss: 0.8111 - acc: 0.5208     \n",
      "Epoch 3/10\n",
      "129595/129595 [==============================] - 3s - loss: 0.8107 - acc: 0.5220     \n",
      "Epoch 4/10\n",
      "129595/129595 [==============================] - 3s - loss: 0.8105 - acc: 0.5223     \n",
      "Epoch 5/10\n",
      "129595/129595 [==============================] - 3s - loss: 0.8104 - acc: 0.5227     \n",
      "Epoch 6/10\n",
      "129595/129595 [==============================] - 3s - loss: 0.8102 - acc: 0.5230     \n",
      "Epoch 7/10\n",
      "129595/129595 [==============================] - 4s - loss: 0.8102 - acc: 0.5226     \n",
      "Epoch 8/10\n",
      "129595/129595 [==============================] - 3s - loss: 0.8100 - acc: 0.5227     \n",
      "Epoch 9/10\n",
      "129595/129595 [==============================] - 3s - loss: 0.8101 - acc: 0.5241     \n",
      "Epoch 10/10\n",
      "129595/129595 [==============================] - 3s - loss: 0.8099 - acc: 0.5227     \n",
      "125440/129595 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "################## Train Model ############################\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=7))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "loss_and_metrics = model.evaluate(X_train, y_train, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80944486872282173, 0.52404027932210584]\n"
     ]
    }
   ],
   "source": [
    "print(loss_and_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
